{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependences\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickles\n",
    "def read_pickle(pickle_name):\n",
    "    path = \"../pickles/\"\n",
    "    return pkl.load(open(path+pickle_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(obj, pickle_name):\n",
    "    path = \"../pickles/\"\n",
    "    pkl.dump(obj, open(path+pickle_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_map(labels):\n",
    "    label_dict = {}\n",
    "    temp1 = list(set(labels))\n",
    "    temp2 = [(i+1) for i in range(len(temp1))]\n",
    "    for i in range(len(temp1)):\n",
    "        label_dict[temp1[i]] = int(temp2[i])\n",
    "    mapped_labels = []\n",
    "    for label in labels:\n",
    "        mapped_labels.append(label_dict[label])\n",
    "    return mapped_labels, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(texts):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfs = tfidf.fit_transform(texts)\n",
    "    tfs_df = pd.DataFrame(tfs.A, columns = tfidf.get_feature_names())\n",
    "    vocab = tfidf.get_feature_names()\n",
    "    dump_pickle(tfs_df, 'tfs.pkl')\n",
    "    dump_pickle(vocab, 'tfs_vocab.pkl')\n",
    "    return tfs_df, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def untokenize(texts):\n",
    "    docs = []\n",
    "    for doc in texts:\n",
    "        temp = \"\"\n",
    "        for word in doc:\n",
    "            temp += word + \" \"\n",
    "        docs.append(temp)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2v(texts, size):\n",
    "    model = Word2Vec(texts, size = size)\n",
    "    word_dict = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "    dump_pickle(word_dict, 'w2v_dict.pkl')\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2v(texts, word_dict, size):\n",
    "    doc_vecs = []\n",
    "    for doc in texts:\n",
    "        counter = 0\n",
    "        vecs = np.zeros(size)\n",
    "        for words in doc:\n",
    "            if words in word_dict:\n",
    "                vecs = np.add(vecs,word_dict[words])\n",
    "                counter += 1\n",
    "        vecs = np.divide(vecs,counter)\n",
    "        doc_vecs.append(vecs)\n",
    "    dump_pickle(doc_vecs, 'doc_vecs.pkl')\n",
    "    return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# texts = list of documents\n",
    "# tfs_df = dataframe of tfidf values\n",
    "# word_dict = dict that maps words to w2v vectors\n",
    "# vocab = vocabulary of tfidf\n",
    "# size = size of w2v vectors\n",
    "def tfidf_d2v(texts, tfs_df, word_dict, vocab, size):\n",
    "    doc_vecs = []\n",
    "    for i in range(len(tfs_df)):\n",
    "        n = 0\n",
    "        vectors = [0]*size\n",
    "        for word in vocab:\n",
    "            if word in word_dict:\n",
    "                vectors += word_dict[word]*tfs_df[word][i]\n",
    "                n += 1\n",
    "        doc_vecs.append([i/n for i in vectors])\n",
    "    dump_pickle(doc_vecs, 'weighted_doc_vecs.pkl')\n",
    "    return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne(vecs, model_name, perplexity = 30):\n",
    "    model_tsne = TSNE(n_components=2, verbose = 1, perplexity = perplexity,\n",
    "                  learning_rate = 30, random_state=0)\n",
    "    tsne = model_tsne.fit_transform(vecs)\n",
    "    dump_pickle(tsne, model_name+\"_tsne.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 534 / 534\n",
      "[t-SNE] Mean sigma: 0.281165\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.891549\n",
      "[t-SNE] Error after 300 iterations: 1.891549\n",
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 534 / 534\n",
      "[t-SNE] Mean sigma: 0.150990\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.515203\n",
      "[t-SNE] Error after 375 iterations: 1.515203\n",
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 534 / 534\n",
      "[t-SNE] Mean sigma: 0.000532\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.438098\n",
      "[t-SNE] Error after 325 iterations: 1.438098\n"
     ]
    }
   ],
   "source": [
    "labels = read_pickle(\"cleaned_train_data.pkl\")['labels']\n",
    "texts = read_pickle(\"cleaned_train_data.pkl\")['texts']\n",
    "size = 50\n",
    "tfs_df, vocab = tf_idf(untokenize(texts))\n",
    "dic = w2v(texts, size)\n",
    "doc_vecs = d2v(texts, dic, size)\n",
    "weighted_doc_vecs = tfidf_d2v(texts, tfs_df, dic, vocab, size)\n",
    "tsne(tfs_df, \"tfidf\")\n",
    "tsne(doc_vecs, \"d2v\")\n",
    "tsne(weighted_doc_vecs, \"weighted_d2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
